{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transliterate\n",
    "import googletrans\n",
    "import geonamescache\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "USSR_codes = ['RU', 'LV', 'AM', 'UA', 'BY', 'RU-DA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_dict = {\n",
    "    'Tolmachevo': 'Novosibirsk', \n",
    "    'Koltsovo': 'Ekaterinburg',\n",
    "    'Kurumoch': 'Samara',\n",
    "    'Vityazevo': 'Anapa',\n",
    "    'Platov': 'Rostov-na-Donu',\n",
    "    'Vnukovo': 'Moscow',\n",
    "    'Domodedovo': 'Moscow',\n",
    "    \"Sheremet'evo\": 'Moscow',\n",
    "    \"Moskva Oktjabr'skaja\": 'Moscow',\n",
    "    'Nizhnevo': 'Barnaul' #Because the flight number matches Barnaul flight\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_сity_name(phrase):\n",
    "    if any([x.lower() in phrase.lower() \n",
    "        for x in np.unique(sng_cities.city)]):\n",
    "        indeces = np.where([x.lower() in phrase.lower() \n",
    "        for x in sng_cities.city]\n",
    "                )\n",
    "        corrected_names = np.unique(sng_cities.iloc[indeces].city)\n",
    "        corrected_names = sorted(corrected_names, key = lambda x: len(x), reverse=True)\n",
    "        return(corrected_names[0])\n",
    "    else:\n",
    "        indeces = np.where([x.lower() in phrase.lower() \n",
    "            for x in sng_cities.alternative_name]\n",
    "                    )\n",
    "        corrected_names = np.unique(sng_cities.iloc[indeces].city)\n",
    "        corrected_names = sorted(corrected_names, key = lambda x: len(x), reverse=True)\n",
    "        if len(corrected_names) == 0:\n",
    "            return np.NaN\n",
    "        else: \n",
    "            return(corrected_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_сity_name(phrase, check_main_names = True):\n",
    "    if check_main_names:\n",
    "        city = string_against_set(phrase, sng_cities.city.values)\n",
    "    else:\n",
    "        city = None\n",
    "    if city is None:\n",
    "        city = string_against_set(phrase, sng_cities.alternative_name.values)\n",
    "        if city is not None:\n",
    "            city = np.unique(sng_cities.query('alternative_name == @city').city.values)[0]\n",
    "    return(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_against_set(string, set_of_strings):\n",
    "    indeces = np.where([x.lower() in string.lower() \n",
    "                        for x in set_of_strings])[0]\n",
    "    if len(indeces) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        names = np.unique(set_of_strings[indeces])\n",
    "        names = sorted(names, key = lambda x: len(x), reverse=True)\n",
    "        return(names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def airport_to_city(string):\n",
    "    city = string_against_set(string, np.array(list(airport_dict.keys()))\n",
    "                             )\n",
    "    if city is not None:\n",
    "        return(airport_dict[city])\n",
    "    else:\n",
    "        return(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.ExcelFile(\"../data/_FSB Poison Squad Travel History_no_comments.ods\", engine=\"odf\")\n",
    "names = file.sheet_names  # see all sheet names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame()\n",
    "for name in names[1:]:\n",
    "    data = file.parse(\n",
    "            sheet_name=name,\n",
    "            keep_default_na = True, \n",
    "            na_filter = True,\n",
    "            encoding='cp1251'\n",
    "                )\n",
    "    data.Date = pd.to_datetime(data.Date)\n",
    "    data.dropna(how = 'all', inplace = True)\n",
    "    data['Name'] = name\n",
    "    all_data = pd.concat((\n",
    "        all_data,\n",
    "        data\n",
    "    ),\n",
    "        ignore_index = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Departure_original'] = all_data['Departure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Arrival_original'] = all_data['Arrival']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harmonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.Departure = all_data.Departure.apply(lambda x: x.split(',')[0])\n",
    "all_data.Arrival = all_data.Arrival.apply(lambda x: x.split(',')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transliterate to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_to_en = lambda x: transliterate.translit(x, \"ru\", reversed=True).lower()\n",
    "translate_to_ru = lambda x: transliterate.translit(x, \"ru\", reversed=False).lower()\n",
    "get_language = lambda x: 'ru' if transliterate.detect_language(x) == 'ru' else 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['language'] = all_data.Departure.apply(get_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Departure_en'] = all_data.Departure\n",
    "all_data['Arrival_en'] = all_data.Arrival\n",
    "\n",
    "all_data.loc[all_data.language == 'ru', 'Departure_en'] = all_data.query('language == \"ru\"').Departure.apply(translate_to_en)\n",
    "all_data.loc[all_data.language == 'ru', 'Arrival_en'] = all_data.query('language == \"ru\"').Arrival.apply(translate_to_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace airport names with city names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.Departure_en = all_data.Departure_en.apply(airport_to_city)\n",
    "all_data.Arrival_en = all_data.Arrival_en.apply(airport_to_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transliterate to Russian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Departure_ru'] = all_data.Departure\n",
    "all_data['Arrival_ru'] = all_data.Arrival\n",
    "\n",
    "all_data.loc[all_data.language == 'en', 'Departure_ru'] = all_data.query('language == \"en\"').Departure.apply(translate_to_ru)\n",
    "all_data.loc[all_data.language == 'en', 'Arrival_ru'] = all_data.query('language == \"en\"').Arrival.apply(translate_to_ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract city names from db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = geonamescache.GeonamesCache()\n",
    "\n",
    "cities = gc.get_cities()\n",
    "\n",
    "cities_df = pd.DataFrame(\n",
    "[[x, cities[x]['name'], cities[x]['countrycode']] for x in cities.keys()],\n",
    "columns = ('code', 'city', 'country')\n",
    ")\n",
    "\n",
    "sng_cities = cities_df.query('country in @USSR_codes')\n",
    "sng_cities = pd.DataFrame(\n",
    "[[x, \n",
    " cities[x]['name'], \n",
    " cities[x]['countrycode'],\n",
    " cities[x]['alternatenames'] + [cities[x]['name']] + [cities[x]['name'].replace('-', ' ')]] for x in sng_cities.code],\n",
    "columns = ('code', 'city', 'country', 'alternative_name')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sng_cities = sng_cities.explode('alternative_name').reset_index(drop=True)\n",
    "\n",
    "sng_cities.loc[\n",
    "    sng_cities.alternative_name == '', \n",
    "    'alternative_name'] = sng_cities.loc[\n",
    "                                sng_cities.alternative_name == '', \n",
    "                                'city']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disambiguate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sng_cities.drop(index = sng_cities[(sng_cities.city == \"Rostov-na-Donu\") &\n",
    "                                   (sng_cities.alternative_name == 'Rostov')].index,\n",
    "               inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sng_cities.drop(index = sng_cities[(sng_cities.city == \"Korolev\") &\n",
    "                                   (sng_cities.alternative_name == 'Kaliningrad')].index,\n",
    "               inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add city names to data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try to find english names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[all_data.language == 'en',\n",
    "         'Departure_corrected'] = all_data.loc[all_data.language == 'en',\n",
    "                                          'Departure_en'].apply(find_сity_name)\n",
    "\n",
    "all_data.loc[all_data.language == 'en',\n",
    "         'Arrival_corrected'] = all_data.loc[all_data.language == 'en',\n",
    "                                         'Arrival_en'].apply(find_сity_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[all_data.language == 'ru',\n",
    "         'Departure_corrected'] = all_data.loc[all_data.language == 'ru',\n",
    "                                          'Departure_en'].apply(lambda x: find_сity_name(x, \n",
    "                                                                                         check_main_names=False))\n",
    "\n",
    "all_data.loc[all_data.language == 'ru',\n",
    "         'Arrival_corrected'] = all_data.loc[all_data.language == 'ru',\n",
    "                                         'Arrival_en'].apply(lambda x: find_сity_name(x, \n",
    "                                                                                         check_main_names=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try russian names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[\n",
    "    pd.isna(all_data.Departure_corrected),\n",
    "    'Departure_corrected'] = all_data[\n",
    "                                pd.isna(all_data.Departure_corrected)\n",
    "                            ].Departure_ru.apply(lambda x: find_сity_name(x, check_main_names=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[\n",
    "    pd.isna(all_data.Arrival_corrected),\n",
    "    'Arrival_corrected'] = all_data[\n",
    "                                pd.isna(all_data.Arrival_corrected)\n",
    "                            ].Arrival_ru.apply(lambda x: find_сity_name(x, check_main_names=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[pd.isna(all_data.Arrival_corrected), \n",
    "             'Arrival_corrected'] = all_data.loc[pd.isna(all_data.Arrival_corrected),\n",
    "                                                 'Arrival_en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[pd.isna(all_data.Departure_corrected),\n",
    "        'Departure_corrected'] = all_data.loc[pd.isna(all_data.Departure_corrected),\n",
    "                                            'Departure_en']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ['Osnovnoy', 'zapadnaja dvina', 'pashkovskaja']:\n",
    "    for col_name in ['Arrival', 'Departure']:\n",
    "        all_data.loc[all_data[f'{col_name}_en'] == name,\n",
    "                     f'{col_name}_corrected'] = all_data.loc[all_data[f'{col_name}_en'] == name,\n",
    "                                                             f'{col_name}_en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in ['Arrival', 'Departure']:\n",
    "        all_data.loc[all_data[f'{col_name}_en'] == \"brjansk orlovskij\",\n",
    "                     f'{col_name}_corrected'] = 'Bryansk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capitalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.Departure_corrected = all_data.Departure_corrected.apply(lambda x: x.title())\n",
    "all_data.Arrival_corrected = all_data.Arrival_corrected.apply(lambda x: x.title())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Departure_country'] = all_data.Departure_corrected.apply(lambda x: np.unique(sng_cities.query('city == @x').country)\n",
    "                                  )\n",
    "\n",
    "all_data.Departure_country = all_data.Departure_country.explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Arrival_country'] = all_data.Arrival_corrected.apply(lambda x: np.unique(sng_cities.query('city == @x').country)\n",
    "                                  )\n",
    "\n",
    "all_data.Arrival_country = all_data.Arrival_country.explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_to_save = all_data[['Date', 'Name', 'Departure_original', 'Arrival_original', 'Notes', \n",
    "                             'Departure_corrected', 'Arrival_corrected', 'Departure_country',\n",
    "                            'Arrival_country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_to_save.to_csv('../data/FSB_poison_squad_travel_history_harmonized.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"my_user_agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.Arrival_corrected = all_data.Arrival_corrected.astype(str)\n",
    "all_data.Departure_corrected = all_data.Departure_corrected.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Arrival_location'] = all_data.Arrival_corrected + ','+ all_data.Arrival_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Arrival_loc'] = all_data['Arrival_location'].apply(\n",
    "    geolocator.geocode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_journalism]",
   "language": "python",
   "name": "conda-env-data_journalism-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
